# å¯¼å…¥å¿…è¦çš„åº“
import streamlit as st  # Streamlitç”¨äºæ„å»ºWebåº”ç”¨ç•Œé¢
import pandas as pd     # Pandasç”¨äºæ•°æ®å¤„ç†å’Œåˆ†æ
import numpy as np      # NumPyç”¨äºæ•°å€¼è®¡ç®—
import os               # æ“ä½œç³»ç»Ÿæ¥å£
import sys              # ç³»ç»Ÿç›¸å…³åŠŸèƒ½
import logging          # æ—¥å¿—è®°å½•
from pathlib import Path  # è·¯å¾„æ“ä½œå·¥å…·
from datetime import datetime  # æ—¥æœŸæ—¶é—´å¤„ç†

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„ï¼Œä»¥ä¾¿èƒ½å¤Ÿå¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.append(str(Path(__file__).parent.parent))

# åˆ›å»ºæ—¥å¿—ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
app_dir = str(Path(__file__).parent.parent)
logs_dir = os.path.join(app_dir, "logs")
if not os.path.exists(logs_dir):
    os.makedirs(logs_dir)

# è®¾ç½®æ—¥å¿—è®°å½•
def setup_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶åï¼ˆåŒ…å«æ—¥æœŸï¼‰
    log_filename = os.path.join(logs_dir, f"app_{datetime.now().strftime('%Y%m%d')}.log")

    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

    # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setFormatter(log_format)

    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(log_format)

    # è·å–æ ¹æ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)

    # æ¸…é™¤ç°æœ‰å¤„ç†å™¨ï¼ˆé¿å…é‡å¤ï¼‰
    if logger.handlers:
        logger.handlers.clear()

    # æ·»åŠ å¤„ç†å™¨
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger

# åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
logger = setup_logging()

# æ£€æŸ¥æ˜¯å¦å·²ç»è®°å½•è¿‡å¯åŠ¨ä¿¡æ¯
if 'app_started_logged' not in st.session_state:
    logger.info("è´å¶æ–¯ä¼˜åŒ–ææ–™ç»„åˆ†ç³»ç»Ÿå¯åŠ¨ä¸­...")
    # æ ‡è®°ä¸ºå·²è®°å½•
    st.session_state.app_started_logged = True

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from app.utils.data_processor import DataProcessor  # æ•°æ®å¤„ç†å·¥å…·ç±»
from app.models.model_trainer import ModelTrainer    # æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ç±»
from app.optimization.bayesian_optimizer import BayesianOptimizer  # è´å¶æ–¯ä¼˜åŒ–å™¨ç±»

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="è´å¶æ–¯ä¼˜åŒ–ææ–™ç»„åˆ†ç³»ç»Ÿ",  # é¡µé¢æ ‡é¢˜
    page_icon="ğŸ§ª",                     # é¡µé¢å›¾æ ‡
    layout="wide",                      # ä½¿ç”¨å®½å¸ƒå±€
    initial_sidebar_state="expanded"    # åˆå§‹ä¾§è¾¹æ çŠ¶æ€ä¸ºå±•å¼€
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼Œç”¨äºåœ¨ä¸åŒé¡µé¢é—´å…±äº«æ•°æ®
if 'data' not in st.session_state:
    st.session_state.data = None  # å­˜å‚¨ä¸Šä¼ çš„æ•°æ®
if 'features' not in st.session_state:
    st.session_state.features = None  # å­˜å‚¨é€‰æ‹©çš„ç‰¹å¾åˆ—
if 'target' not in st.session_state:
    st.session_state.target = None  # å­˜å‚¨é€‰æ‹©çš„ç›®æ ‡åˆ—
if 'model' not in st.session_state:
    st.session_state.model = None  # å­˜å‚¨è®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹
if 'best_model_name' not in st.session_state:
    st.session_state.best_model_name = None  # å­˜å‚¨æœ€ä½³æ¨¡å‹åç§°
if 'feature_ranges' not in st.session_state:
    st.session_state.feature_ranges = {}  # å­˜å‚¨ç‰¹å¾çš„èŒƒå›´ä¿¡æ¯
if 'recommendations' not in st.session_state:
    st.session_state.recommendations = None  # å­˜å‚¨ä¼˜åŒ–æ¨èç»“æœ
if 'optimization_history' not in st.session_state:
    st.session_state.optimization_history = []  # å­˜å‚¨ä¼˜åŒ–å†å²è®°å½•
if 'n_bootstraps' not in st.session_state:
    st.session_state.n_bootstraps = 50  # é»˜è®¤Bootstrapæ¨¡å‹æ•°é‡ï¼Œç”¨äºéGPå’Œééšæœºæ£®æ—æ¨¡å‹çš„ä¸ç¡®å®šæ€§ä¼°è®¡
if 'data_processor' not in st.session_state:
    st.session_state.data_processor = DataProcessor() # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨

# ä¸»é¡µé¢æ ‡é¢˜
st.title("è´å¶æ–¯ä¼˜åŒ–ææ–™ç»„åˆ†ç³»ç»Ÿ")

# ä¾§è¾¹æ å¯¼èˆª
st.sidebar.title("å¯¼èˆª")
page = st.sidebar.radio(
    "é€‰æ‹©åŠŸèƒ½é¡µé¢",
    ["æ•°æ®ä¸Šä¼ ä¸å¤„ç†", "æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°", "ç‰¹å¾è¾“å…¥ä¸é¢„æµ‹", "æœç´¢æ¨è", "è¿­ä»£ä¼˜åŒ–"] # æ›´æ–°é¡µé¢åˆ—è¡¨
)

# æ•°æ®ä¸Šä¼ ä¸å¤„ç†é¡µé¢
if page == "æ•°æ®ä¸Šä¼ ä¸å¤„ç†":
    """
    æ•°æ®ä¸Šä¼ ä¸å¤„ç†é¡µé¢åŠŸèƒ½ï¼š
    1. å…è®¸ç”¨æˆ·ä¸Šä¼ CSVæ ¼å¼çš„æ•°æ®æ–‡ä»¶
    2. é¢„è§ˆä¸Šä¼ çš„æ•°æ®
    3. é€‰æ‹©ç‰¹å¾åˆ—å’Œç›®æ ‡åˆ—
    4. åˆå§‹åŒ–ç‰¹å¾èŒƒå›´ä¿¡æ¯
    """
    st.header("æ•°æ®ä¸Šä¼ ä¸å¤„ç†")

    # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶ï¼Œé™åˆ¶ä¸ºCSVæ ¼å¼
    uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type=["csv"])

    if uploaded_file is not None:
        try:
            # è¯»å–ä¸Šä¼ çš„CSVæ–‡ä»¶æ•°æ®
            data = pd.read_csv(uploaded_file, index_col=0)
            # å°†æ•°æ®å­˜å…¥ä¼šè¯çŠ¶æ€ï¼Œä¾›å…¶ä»–é¡µé¢ä½¿ç”¨
            st.session_state.data = data

            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            st.subheader("æ•°æ®é¢„è§ˆ")
            # æ˜¾ç¤ºæ•°æ®å‰5è¡Œï¼Œè®©ç”¨æˆ·ç¡®è®¤æ•°æ®æ ¼å¼æ­£ç¡®
            st.dataframe(data.head())

            # é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡åˆ—
            st.subheader("é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡åˆ—")
            # è·å–æ•°æ®æ‰€æœ‰åˆ—å
            all_columns = data.columns.tolist()

            # é€‰æ‹©ç‰¹å¾åˆ—
            features = st.multiselect(
                "é€‰æ‹©ç‰¹å¾åˆ—",
                all_columns,
                default=all_columns[:-1]  # é»˜è®¤é€‰æ‹©é™¤æœ€åä¸€åˆ—å¤–çš„æ‰€æœ‰åˆ—
            )

            # é€‰æ‹©ç›®æ ‡åˆ—
            remaining_columns = [col for col in all_columns if col not in features]
            target = st.selectbox("é€‰æ‹©ç›®æ ‡åˆ—", remaining_columns)

            if st.button("ç¡®è®¤é€‰æ‹©"):
                if len(features) > 0 and target:
                    st.session_state.features = features
                    st.session_state.target = target

                    # åˆå§‹åŒ–ç‰¹å¾èŒƒå›´
                    feature_ranges = {}
                    for feature in features:
                        min_val = float(data[feature].min())
                        max_val = float(data[feature].max())
                        feature_ranges[feature] = {
                            "min": min_val,
                            "max": max_val,
                            "step": (max_val - min_val) / 10  # é»˜è®¤æ­¥é•¿
                        }
                    st.session_state.feature_ranges = feature_ranges

                    st.success(f"å·²é€‰æ‹© {len(features)} ä¸ªç‰¹å¾åˆ—å’Œ '{target}' ä½œä¸ºç›®æ ‡åˆ—")
                else:
                    st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾åˆ—å’Œä¸€ä¸ªç›®æ ‡åˆ—")

        except Exception as e:
            error_msg = f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}"
            logger.error(error_msg, exc_info=True)
            st.error(error_msg)

# æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°é¡µé¢
elif page == "æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°":
    """
    æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°é¡µé¢åŠŸèƒ½ï¼š
    1. é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹ç±»å‹
    2. è®¾ç½®è¯„ä¼°æŒ‡æ ‡å’Œè®­ç»ƒå‚æ•°
    3. è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹æ€§èƒ½
    4. é€‰æ‹©æœ€ä½³æ¨¡å‹ç”¨äºåç»­ä¼˜åŒ–
    """
    st.header("æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°")

    # æ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ æ•°æ®å¹¶é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡åˆ—
    if st.session_state.data is None or st.session_state.features is None or st.session_state.target is None:
        st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®å¹¶é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡åˆ—")
    else:
        st.info(f"å½“å‰æ•°æ®é›†: {st.session_state.data.shape[0]} è¡Œ, {st.session_state.data.shape[1]} åˆ—")
        st.info(f"é€‰æ‹©çš„ç‰¹å¾: {', '.join(st.session_state.features)}")
        st.info(f"é€‰æ‹©çš„ç›®æ ‡: {st.session_state.target}")

        # æ¨¡å‹é€‰æ‹©
        st.subheader("æ¨¡å‹é€‰æ‹©")
        # æä¾›å¤šç§å›å½’æ¨¡å‹é€‰é¡¹ï¼Œç”¨æˆ·å¯å¤šé€‰
        models_to_train = st.multiselect(
            "é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹",
            ["Lasso", "éšæœºæ£®æ—", "XGBoost", "SVR", "é«˜æ–¯è¿‡ç¨‹"],
            default=["Lasso", "éšæœºæ£®æ—", "XGBoost", "SVR", "é«˜æ–¯è¿‡ç¨‹"]
        )

        # è¯„ä¼°æŒ‡æ ‡é€‰æ‹©
        metric = st.radio("é€‰æ‹©è¯„ä¼°æŒ‡æ ‡", ["RÂ²", "RMSE"])

        # è®­ç»ƒæµ‹è¯•é›†åˆ’åˆ†æ¯”ä¾‹
        test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05)

        # äº¤å‰éªŒè¯æŠ˜æ•°
        cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", 3, 10, 5, 1)

        if st.button("è®­ç»ƒæ¨¡å‹"):
            with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¨å€™..."):
                try:
                    # å‡†å¤‡æ•°æ®
                    X_original = st.session_state.data[st.session_state.features]
                    y = st.session_state.data[st.session_state.target]

                    # åº”ç”¨ç‰¹å¾ç¼©æ”¾
                    logger.info("åº”ç”¨ç‰¹å¾ç¼©æ”¾...")
                    X_scaled = st.session_state.data_processor.scale_features(X_original.copy(), st.session_state.features) # ä½¿ç”¨å‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                    logger.info(f"ç‰¹å¾ç¼©æ”¾å®Œæˆã€‚Scaler: {st.session_state.data_processor.scaler}")

                    # åˆå§‹åŒ–æ¨¡å‹è®­ç»ƒå™¨
                    trainer = ModelTrainer(
                        models=models_to_train,
                        metric=metric.lower(),
                        cv_folds=cv_folds,
                        test_size=test_size
                    )

                    # ä½¿ç”¨ç¼©æ”¾åçš„æ•°æ®è®­ç»ƒæ¨¡å‹
                    logger.info("å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
                    results = trainer.train_and_evaluate(X_scaled, y)
                    logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

                    # æ˜¾ç¤ºç»“æœ
                    st.subheader("æ¨¡å‹è¯„ä¼°ç»“æœ")

                    # åˆ›å»ºç»“æœæ•°æ®æ¡†
                    results_df = pd.DataFrame(results).sort_values(
                        by="cv_score",
                        ascending=True if metric.lower() == "rmse" else False
                    )

                    # æ ¼å¼åŒ–ç»“æœ
                    results_df["test_score"] = results_df["test_score"].apply(lambda x: f"{x:.4f}")
                    results_df["cv_score"] = results_df["cv_score"].apply(lambda x: f"{x:.4f}")
                    results_df["train_score"] = results_df["train_score"].apply(lambda x: f"{x:.4f}")

                    # æ˜¾ç¤ºç»“æœè¡¨æ ¼
                    display_df = pd.DataFrame([{
                        'æ¨¡å‹åç§°': r['model_name'],
                        'æµ‹è¯•åˆ†æ•°': r['test_score'],
                        'äº¤å‰éªŒè¯åˆ†æ•°': r['cv_score'],
                        'è®­ç»ƒåˆ†æ•°': r['train_score']
                    } for r in results])

                    st.dataframe(display_df)

                    # è·å–æœ€ä½³æ¨¡å‹
                    best_model_name = results_df.iloc[0]["model_name"]
                    best_model = trainer.get_best_model()

                    # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                    st.session_state.model = best_model
                    st.session_state.best_model_name = best_model_name

                    st.success(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹: {best_model_name}")
                    st.info(f"ç‰¹å¾ç¼©æ”¾å™¨ (Scaler) å·²æ‹Ÿåˆå¹¶å­˜å‚¨ã€‚")

                except Exception as e:
                    error_msg = f"æ¨¡å‹è®­ç»ƒæ—¶å‡ºé”™: {str(e)}"
                    logger.error(error_msg, exc_info=True)
                    st.error(error_msg)

# ç‰¹å¾è¾“å…¥ä¸é¢„æµ‹é¡µé¢ (æ–°é¡µé¢)
elif page == "ç‰¹å¾è¾“å…¥ä¸é¢„æµ‹":
    st.header("ç‰¹å¾è¾“å…¥ä¸é¢„æµ‹")

    if st.session_state.model is None:
        st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
    elif st.session_state.features is None:
        st.warning("è¯·å…ˆåœ¨'æ•°æ®ä¸Šä¼ ä¸å¤„ç†'é¡µé¢é€‰æ‹©ç‰¹å¾")
    else:
        st.info(f"å½“å‰æœ€ä½³æ¨¡å‹: {st.session_state.best_model_name}")
        st.markdown("åœ¨ä¸‹æ–¹è¾“å…¥ç‰¹å¾å€¼ï¼Œè·å–é¢„æµ‹ç»“æœ")

        # åˆ›å»ºå¤šåˆ—å¸ƒå±€ç”¨äºè¾“å…¥ç‰¹å¾å€¼
        feature_values = {}
        cols = st.columns(3)

        for i, feature in enumerate(st.session_state.features):
            col_idx = i % 3
            with cols[col_idx]:
                # è·å–å½“å‰èŒƒå›´ä½œä¸ºå‚è€ƒ
                current_range = st.session_state.feature_ranges.get(feature, {})
                min_val = current_range.get("min", 0.0)
                max_val = current_range.get("max", 1.0)
                default_val = float((min_val + max_val) / 2)  # é»˜è®¤å€¼ä¸ºèŒƒå›´ä¸­ç‚¹

                # ä½¿ç”¨æ–‡æœ¬è¾“å…¥æ¡†è¾“å…¥ç‰¹å¾å€¼
                st.markdown(f"**{feature}** (èŒƒå›´: {min_val:.4f} - {max_val:.4f})")
                # ä½¿ç”¨ number_input æ›¿ä»£ text_input ä»¥ä¾¿æ›´å¥½åœ°å¤„ç†æ•°å€¼
                feature_values[feature] = st.number_input(
                    f"è¾“å…¥{feature}çš„å€¼",
                    value=default_val,
                    format="%.4f", # ä¿æŒæ ¼å¼
                    key=f"input_{feature}"
                )

        # é¢„æµ‹æŒ‰é’®
        if st.button("è·å–é¢„æµ‹ç»“æœ"):
            try:
                # æ£€æŸ¥ scaler æ˜¯å¦å·²æ‹Ÿåˆ
                if not hasattr(st.session_state.data_processor, 'scaler') or not hasattr(st.session_state.data_processor.scaler, 'mean_'):
                     st.error("ç‰¹å¾ç¼©æ”¾å™¨ (Scaler) å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹ã€‚")
                else:
                    # å°†è¾“å…¥çš„ç‰¹å¾å€¼è½¬æ¢ä¸ºDataFrameï¼Œå¹¶æŒ‰è®­ç»ƒæ—¶çš„é¡ºåºæ’åˆ—
                    input_df_original = pd.DataFrame([feature_values])[st.session_state.features]

                    # ä½¿ç”¨å­˜å‚¨çš„ scaler è¿›è¡Œè½¬æ¢
                    input_df_scaled = st.session_state.data_processor.scaler.transform(input_df_original)
                    input_df_scaled = pd.DataFrame(input_df_scaled, columns=st.session_state.features) # è½¬æ¢å›DataFrame

                    # ä½¿ç”¨ç¼©æ”¾åçš„æ•°æ®è¿›è¡Œé¢„æµ‹
                    prediction = st.session_state.model.predict(input_df_scaled)[0]

                    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                    st.success(f"é¢„æµ‹ç»“æœ: {prediction:.4f}")

                    # åˆ›å»ºåŒ…å«é¢„æµ‹ç»“æœçš„DataFrameç”¨äºå±•ç¤º
                    result_df = pd.DataFrame([feature_values])
                    result_df[st.session_state.target] = prediction # å‡è®¾ç›®æ ‡åˆ—åå·²å­˜å‚¨
                    st.dataframe(result_df)

            except Exception as e:
                error_msg = f"é¢„æµ‹æ—¶å‡ºé”™: {str(e)}"
                logger.error(error_msg, exc_info=True)
                st.error(error_msg)
                st.info("æç¤ºï¼šè¯·ç¡®ä¿æ‰€æœ‰ç‰¹å¾å€¼éƒ½åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼Œå¹¶ä¸”æ ¼å¼æ­£ç¡®ã€‚")

# æœç´¢æ¨èé¡µé¢ (åŸç‰¹å¾ç©ºé—´å®šä¹‰ä¸ä¼˜åŒ–é¡µé¢ï¼Œå·²é‡å‘½å)
elif page == "æœç´¢æ¨è":
    st.header("æœç´¢æ¨è") # æ›´æ–°æ ‡é¢˜

    if st.session_state.model is None:
        st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
    elif st.session_state.features is None:
        st.warning("è¯·å…ˆåœ¨'æ•°æ®ä¸Šä¼ ä¸å¤„ç†'é¡µé¢é€‰æ‹©ç‰¹å¾")
    else:
        st.info(f"å½“å‰æœ€ä½³æ¨¡å‹: {st.session_state.best_model_name}")

        # ç‰¹å¾ç©ºé—´å®šä¹‰
        st.subheader("ç‰¹å¾ç©ºé—´å®šä¹‰")

        # åˆ›å»ºå¤šåˆ—å¸ƒå±€
        feature_ranges_input = {} # ä½¿ç”¨æ–°å˜é‡åé¿å…è¦†ç›–ä¼šè¯çŠ¶æ€
        cols = st.columns(3)

        for i, feature in enumerate(st.session_state.features):
            col_idx = i % 3
            with cols[col_idx]:
                st.markdown(f"**{feature}**")

                # è·å–å½“å‰èŒƒå›´
                current_range = st.session_state.feature_ranges.get(feature, {})
                min_val = current_range.get("min", 0.0)
                max_val = current_range.get("max", 1.0)
                step = current_range.get("step", 0.1)

                # è®¾ç½®èŒƒå›´å’Œæ­¥é•¿
                new_min = st.number_input(f"{feature} æœ€å°å€¼", value=float(min_val), format="%.4f", key=f"min_{feature}")
                new_max = st.number_input(f"{feature} æœ€å¤§å€¼", value=float(max_val), format="%.4f", key=f"max_{feature}")
                new_step = st.number_input(f"{feature} æ­¥é•¿", value=float(step), format="%.4f", min_value=0.0, key=f"step_{feature}") # æ­¥é•¿ä¸èƒ½ä¸ºè´Ÿ

                feature_ranges_input[feature] = {
                    "min": new_min,
                    "max": new_max,
                    "step": new_step
                }

        if st.button("æ›´æ–°ç‰¹å¾ç©ºé—´å¹¶è®¡ç®—ä¿¡æ¯"):
            # éªŒè¯èŒƒå›´å’Œæ­¥é•¿
            valid_ranges = True
            for feature, ranges in feature_ranges_input.items():
                if ranges["min"] >= ranges["max"]:
                    st.error(f"{feature} çš„æœ€å°å€¼å¿…é¡»å°äºæœ€å¤§å€¼ã€‚")
                    valid_ranges = False
                if ranges["step"] <= 0:
                    st.error(f"{feature} çš„æ­¥é•¿å¿…é¡»å¤§äº 0ã€‚")
                    valid_ranges = False
            
            if valid_ranges:
                st.session_state.feature_ranges = feature_ranges_input
                st.success("ç‰¹å¾ç©ºé—´å·²æ›´æ–°")

                # è®¡ç®—ç‰¹å¾ç©ºé—´å¤§å°å’Œé¢„ä¼°å†…å­˜æ¶ˆè€—
                try:
                    # è·å–Bootstrapæ¨¡å‹æ•°é‡ï¼ˆå¦‚æœåœ¨ä¼šè¯çŠ¶æ€ä¸­å­˜åœ¨ï¼‰
                    n_bootstraps = st.session_state.get('n_bootstraps', 50)

                    # åˆå§‹åŒ–è´å¶æ–¯ä¼˜åŒ–å™¨ï¼Œä¸å†æ‰‹åŠ¨è®¾ç½®ä¸ç¡®å®šåº¦ä¼°è®¡æ–¹æ³•
                    optimizer = BayesianOptimizer(
                        model=st.session_state.model,
                        feature_ranges=st.session_state.feature_ranges,
                        method=None,  # è®¾ä¸ºNoneï¼Œè®©ä¼˜åŒ–å™¨è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ–¹æ³•
                        n_bootstraps=n_bootstraps
                    )

                    # è®¡ç®—ç‰¹å¾ç©ºé—´å¤§å°å’Œé¢„ä¼°å†…å­˜æ¶ˆè€—
                    total_points, memory_mb, warning = optimizer.calculate_grid_size()

                    # æ˜¾ç¤ºç‰¹å¾ç©ºé—´ä¿¡æ¯
                    st.info(f"ç‰¹å¾ç©ºé—´æ€»ç‚¹æ•°: {total_points:,}")
                    st.info(f"é¢„ä¼°å†…å­˜æ¶ˆè€—: {memory_mb:.2f} MB")

                    # æ˜¾ç¤ºå†…å­˜è­¦å‘Šä¿¡æ¯
                    if warning:
                        st.warning(warning)
                    # ä¿ç•™åŸæœ‰çš„è­¦å‘Šé€»è¾‘ä½œä¸ºå¤‡ç”¨
                    elif memory_mb > 1000:  # è¶…è¿‡1GB
                        warning_msg = "ç‰¹å¾ç©ºé—´è¾ƒå¤§ï¼Œå¯èƒ½ä¼šå¯¼è‡´è®¡ç®—é€Ÿåº¦å˜æ…¢æˆ–å†…å­˜ä¸è¶³ã€‚å»ºè®®å¢åŠ æ­¥é•¿æˆ–å‡å°‘ç‰¹å¾èŒƒå›´ã€‚"
                        if optimizer.method == 'bootstrap':
                            warning_msg += f" å½“å‰ä½¿ç”¨Bootstrapæ–¹æ³•({n_bootstraps}ä¸ªæ¨¡å‹)ï¼Œå¯ä»¥è€ƒè™‘å‡å°‘æ¨¡å‹æ•°é‡ä»¥é™ä½å†…å­˜æ¶ˆè€—ã€‚"
                        st.warning(warning_msg)
                except Exception as e:
                    error_msg = f"è®¡ç®—ç‰¹å¾ç©ºé—´ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"
                    logger.error(error_msg, exc_info=True)
                    st.error(error_msg)

        # è´å¶æ–¯ä¼˜åŒ–è®¾ç½®
        st.subheader("è´å¶æ–¯ä¼˜åŒ–è®¾ç½®")

        # æœç´¢ç­–ç•¥é€‰æ‹©
        search_strategy = st.selectbox(
            "é€‰æ‹©ä¼˜åŒ–æœç´¢ç­–ç•¥",
            ["ç½‘æ ¼æœç´¢", "é—ä¼ ç®—æ³•", "ç²’å­ç¾¤ä¼˜åŒ–", "æ¨¡æ‹Ÿé€€ç«", "éšæœºæœç´¢"],
            index=0,
            key="search_strategy_select" # æ·»åŠ keyé¿å…å†²çª
        )

        # å°†ä¸­æ–‡ç­–ç•¥åç§°æ˜ å°„åˆ°è‹±æ–‡æ ‡è¯†ç¬¦
        strategy_mapping = {
            "ç½‘æ ¼æœç´¢": "grid",
            "é—ä¼ ç®—æ³•": "ga",
            "ç²’å­ç¾¤ä¼˜åŒ–": "pso",
            "æ¨¡æ‹Ÿé€€ç«": "sa",
            "éšæœºæœç´¢": "random"
        }
        selected_strategy_key = strategy_mapping[search_strategy] # è·å–æ˜ å°„åçš„ç­–ç•¥é”®

        # --- é«˜çº§æœç´¢ç­–ç•¥å‚æ•°è¾“å…¥ ---
        strategy_params = {}
        if selected_strategy_key == 'ga':
            st.subheader("é—ä¼ ç®—æ³•å‚æ•°")
            cols_ga = st.columns(2)
            with cols_ga[0]:
                strategy_params['population_size'] = st.number_input("ç§ç¾¤å¤§å° (population_size)", min_value=10, value=50, step=10, key="ga_pop_size")
                strategy_params['crossover_prob'] = st.slider("äº¤å‰æ¦‚ç‡ (crossover_prob)", 0.0, 1.0, 0.8, 0.05, key="ga_cross_prob")
            with cols_ga[1]:
                strategy_params['n_generations'] = st.number_input("è¿­ä»£ä»£æ•° (n_generations)", min_value=1, value=10, step=1, key="ga_gens")
                strategy_params['mutation_prob'] = st.slider("å˜å¼‚æ¦‚ç‡ (mutation_prob)", 0.0, 1.0, 0.2, 0.05, key="ga_mut_prob")
        elif selected_strategy_key == 'pso':
            st.subheader("ç²’å­ç¾¤ä¼˜åŒ–å‚æ•°")
            cols_pso1 = st.columns(3)
            with cols_pso1[0]:
                strategy_params['n_particles'] = st.number_input("ç²’å­æ•°é‡ (n_particles)", min_value=5, value=30, step=5, key="pso_particles")
            with cols_pso1[1]:
                strategy_params['n_iterations'] = st.number_input("è¿­ä»£æ¬¡æ•° (n_iterations)", min_value=5, value=20, step=5, key="pso_iters")
            with cols_pso1[2]:
                 strategy_params['inertia_weight'] = st.number_input("æƒ¯æ€§æƒé‡ (inertia_weight)", min_value=0.0, value=0.5, step=0.1, format="%.2f", key="pso_inertia")
            cols_pso2 = st.columns(2)
            with cols_pso2[0]:
                strategy_params['cognitive_weight'] = st.number_input("è®¤çŸ¥æƒé‡ (cognitive_weight)", min_value=0.0, value=1.5, step=0.1, format="%.2f", key="pso_cog")
            with cols_pso2[1]:
                strategy_params['social_weight'] = st.number_input("ç¤¾ä¼šæƒé‡ (social_weight)", min_value=0.0, value=1.5, step=0.1, format="%.2f", key="pso_soc")
        elif selected_strategy_key == 'sa':
            st.subheader("æ¨¡æ‹Ÿé€€ç«å‚æ•°")
            cols_sa = st.columns(2)
            with cols_sa[0]:
                strategy_params['n_iterations'] = st.number_input("è¿­ä»£æ¬¡æ•° (n_iterations)", min_value=10, value=100, step=10, key="sa_iters")
                strategy_params['initial_temp'] = st.number_input("åˆå§‹æ¸©åº¦ (initial_temp)", min_value=1.0, value=100.0, step=10.0, format="%.1f", key="sa_temp")
            with cols_sa[1]:
                strategy_params['cooling_rate'] = st.slider("å†·å´ç‡ (cooling_rate)", 0.8, 0.99, 0.95, 0.01, format="%.2f", key="sa_cool")
                strategy_params['n_neighbors'] = st.number_input("é‚»å±…æ•°é‡ (n_neighbors)", min_value=1, value=5, step=1, key="sa_neighbors")
        # --- END ---

        # é‡‡æ ·å‡½æ•°é€‰æ‹©
        acquisition_function = st.selectbox(
            "é€‰æ‹©é‡‡æ ·å‡½æ•°",
            ["EI (æœŸæœ›æ”¹è¿›)", "UCB (ç½®ä¿¡ä¸Šç•Œ)", "PI (æ”¹è¿›æ¦‚ç‡)"],
            key="acq_func_select" # æ·»åŠ key
        )

        # æ˜¾ç¤ºä¸ç¡®å®šåº¦ä¼°è®¡æ–¹æ³•è¯´æ˜
        st.info("ç³»ç»Ÿå°†æ ¹æ®æœ€ä¼˜æ¨¡å‹ç±»å‹è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ä¸ç¡®å®šåº¦ä¼°è®¡æ–¹æ³•ï¼š\n" +
                "- é«˜æ–¯è¿‡ç¨‹æ¨¡å‹ï¼šä½¿ç”¨æ¨¡å‹å†…ç½®çš„ä¸ç¡®å®šåº¦ä¼°è®¡\n" +
                "- éšæœºæ£®æ—æ¨¡å‹ï¼šä½¿ç”¨ä¸åŒå†³ç­–æ ‘çš„é¢„æµ‹æ ‡å‡†å·®\n" +
                "- å…¶ä»–æ¨¡å‹ï¼šä½¿ç”¨Bootstrapæ–¹æ³•ä¼°è®¡ä¸ç¡®å®šåº¦")

        # Bootstrapæ¨¡å‹æ•°é‡è®¾ç½®ï¼ˆç”¨äºéGPå’Œééšæœºæ£®æ—æ¨¡å‹ï¼‰
        n_bootstraps = st.slider(
            "Bootstrapæ¨¡å‹æ•°é‡",
            10, 100, st.session_state.get('n_bootstraps', 50), 5, # ä½¿ç”¨ä¼šè¯çŠ¶æ€æˆ–é»˜è®¤å€¼
            help="å½“ä½¿ç”¨Bootstrapæ–¹æ³•æ—¶ï¼Œæ›´å¤šçš„æ¨¡å‹å¯ä»¥æä¾›æ›´å‡†ç¡®çš„ä¸ç¡®å®šåº¦ä¼°è®¡ï¼Œä½†ä¼šå¢åŠ è®¡ç®—è´Ÿæ‹…å’Œå†…å­˜æ¶ˆè€—ã€‚",
            key="n_bootstraps_slider" # æ·»åŠ key
        )
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        st.session_state.n_bootstraps = n_bootstraps

        # æ¨èå®éªŒæ•°é‡
        n_recommendations = st.slider("æ¨èå®éªŒæ•°é‡", 1, 10, 3, 1, key="n_recs_slider") # æ·»åŠ key

        # ä¼˜åŒ–æ–¹å‘
        optimization_direction = st.radio(
            "ä¼˜åŒ–æ–¹å‘",
            ["æœ€å¤§åŒ–", "æœ€å°åŒ–"],
            index=0,
            key="opt_direction_radio" # æ·»åŠ key
        )

        if st.button("ç”Ÿæˆå®éªŒæ¨è"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆå®éªŒæ¨èï¼Œè¯·ç¨å€™..."):
                try:
                    # å‡†å¤‡åŸå§‹æ•°æ® (ä¼˜åŒ–å™¨å†…éƒ¨ä¼šå¤„ç†ç¼©æ”¾)
                    if st.session_state.data is None:
                         st.error("è¯·å…ˆä¸Šä¼ æ•°æ®ã€‚")
                    elif not hasattr(st.session_state.data_processor, 'scaler') or not hasattr(st.session_state.data_processor.scaler, 'mean_'):
                         st.error("ç‰¹å¾ç¼©æ”¾å™¨ (Scaler) å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹ã€‚")
                    else:
                        X_original = st.session_state.data[st.session_state.features]
                        y = st.session_state.data[st.session_state.target]

                        # åˆå§‹åŒ–è´å¶æ–¯ä¼˜åŒ–å™¨ï¼Œå¹¶ä¼ å…¥æ‹Ÿåˆå¥½çš„ scaler
                        optimizer = BayesianOptimizer(
                            model=st.session_state.model,
                            feature_ranges=st.session_state.feature_ranges,
                            acquisition_function=acquisition_function.split(" ")[0].lower(),
                            maximize=(optimization_direction == "æœ€å¤§åŒ–"),
                            method=None,  # è®¾ä¸ºNoneï¼Œè®©ä¼˜åŒ–å™¨è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ–¹æ³•
                            n_bootstraps=st.session_state.n_bootstraps, # ä»ä¼šè¯çŠ¶æ€è¯»å–
                            search_strategy=selected_strategy_key, # ä½¿ç”¨æ˜ å°„åçš„å€¼
                            search_strategy_params=strategy_params, # ä¼ é€’ç­–ç•¥å‚æ•°
                            scaler=st.session_state.data_processor.scaler # ä¼ å…¥ scaler
                        )

                        # ç”Ÿæˆæ¨è (ä¼˜åŒ–å™¨å†…éƒ¨ä¼šä½¿ç”¨scaler)
                        recommendations = optimizer.recommend_experiments(X_original, y, n_recommendations)

                        # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.recommendations = recommendations

                        # æ˜¾ç¤ºæ¨è
                        st.subheader("å®éªŒæ¨è")
                        st.dataframe(recommendations)

                        # æä¾›ä¸‹è½½é€‰é¡¹
                        csv = recommendations.to_csv(index=False)
                        st.download_button(
                            label="ä¸‹è½½æ¨èå®éªŒæ¡ä»¶",
                            data=csv,
                            file_name="experiment_recommendations.csv",
                            mime="text/csv"
                        )

                except Exception as e:
                    error_msg = f"ç”Ÿæˆå®éªŒæ¨èæ—¶å‡ºé”™: {str(e)}"
                    logger.error(error_msg, exc_info=True)  # è®°å½•å®Œæ•´é”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—
                    st.error(error_msg)
                    st.error("è¯¦ç»†é”™è¯¯ä¿¡æ¯å·²è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶")

# è¿­ä»£ä¼˜åŒ–é¡µé¢
elif page == "è¿­ä»£ä¼˜åŒ–":
    st.header("è¿­ä»£ä¼˜åŒ–")

    if st.session_state.model is None:
        st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
    elif st.session_state.features is None or st.session_state.target is None:
         st.warning("è¯·å…ˆåœ¨'æ•°æ®ä¸Šä¼ ä¸å¤„ç†'é¡µé¢é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡")
    else:
        st.info(f"å½“å‰æœ€ä½³æ¨¡å‹: {st.session_state.best_model_name}")

        # æ˜¾ç¤ºä¼˜åŒ–å†å²
        if len(st.session_state.optimization_history) > 0:
            st.subheader("ä¼˜åŒ–å†å²")

            # åˆ›å»ºå†å²æ•°æ®è¡¨
            history_data = []
            for i, history in enumerate(st.session_state.optimization_history):
                history_data.append({
                    "è¿­ä»£": i + 1,
                    "æ•°æ®é‡": history["data_size"],
                    "æœ€ä½³æ¨¡å‹": history["best_model"],
                    "æœ€ä½³æ€§èƒ½": f"{history['best_score']:.4f}",
                    "ç›®æ ‡æœ€ä¼˜å€¼": f"{history['best_target']:.4f}"
                })

            history_df = pd.DataFrame(history_data)
            st.dataframe(history_df)

            # ç»˜åˆ¶ä¼˜åŒ–è¿›ç¨‹å›¾
            st.subheader("ä¼˜åŒ–è¿›ç¨‹")

            # æå–æ•°æ®ç”¨äºç»˜å›¾
            iterations = [i+1 for i in range(len(st.session_state.optimization_history))]
            best_targets = [h["best_target"] for h in st.session_state.optimization_history]

            # åˆ›å»ºå›¾è¡¨æ•°æ®
            chart_data = pd.DataFrame({
                "è¿­ä»£": iterations,
                "ç›®æ ‡æœ€ä¼˜å€¼": best_targets
            })

            # ç»˜åˆ¶æŠ˜çº¿å›¾
            st.line_chart(chart_data.set_index("è¿­ä»£"))

        # ä¸Šä¼ æ–°å®éªŒæ•°æ®
        st.subheader("ä¸Šä¼ æ–°å®éªŒæ•°æ®")

        uploaded_file = st.file_uploader("ä¸Šä¼ æ–°å®éªŒæ•°æ®CSVæ–‡ä»¶", type=["csv"], key="iter_upload") # æ·»åŠ key

        if uploaded_file is not None:
            try:
                # è¯»å–æ–°æ•°æ®
                new_data = pd.read_csv(uploaded_file)

                # æ£€æŸ¥æ•°æ®æ ¼å¼
                required_columns = st.session_state.features + [st.session_state.target]
                missing_columns = [col for col in required_columns if col not in new_data.columns]

                if missing_columns:
                    st.error(f"æ–°æ•°æ®ç¼ºå°‘ä»¥ä¸‹åˆ—: {', '.join(missing_columns)}")
                else:
                    # æ˜¾ç¤ºæ–°æ•°æ®é¢„è§ˆ
                    st.subheader("æ–°æ•°æ®é¢„è§ˆ")
                    st.dataframe(new_data[required_columns])

                    if st.button("åˆå¹¶æ•°æ®å¹¶æ›´æ–°æ¨¡å‹"):
                        with st.spinner("æ­£åœ¨æ›´æ–°æ¨¡å‹ï¼Œè¯·ç¨å€™..."):
                            # åˆå¹¶æ•°æ®
                            combined_data = pd.concat([st.session_state.data, new_data[required_columns]], ignore_index=True)

                            # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„æ•°æ®
                            st.session_state.data = combined_data

                            # å‡†å¤‡åˆå¹¶åçš„æ•°æ®
                            X_combined_original = combined_data[st.session_state.features]
                            y_combined = combined_data[st.session_state.target]

                            # åœ¨åˆå¹¶åçš„æ•°æ®ä¸Šé‡æ–°æ‹Ÿåˆ Scaler
                            logger.info("åœ¨åˆå¹¶åçš„æ•°æ®ä¸Šé‡æ–°æ‹Ÿåˆ Scaler...")
                            X_combined_scaled = st.session_state.data_processor.scale_features(X_combined_original.copy(), st.session_state.features)
                            logger.info(f"Scaler å·²åœ¨åˆå¹¶æ•°æ®ä¸Šé‡æ–°æ‹Ÿåˆ: {st.session_state.data_processor.scaler}")

                            # é‡æ–°è®­ç»ƒæ¨¡å‹ (ä½¿ç”¨ç¼©æ”¾åçš„æ•°æ®)
                            # éœ€è¦é‡æ–°åˆå§‹åŒ– ModelTrainer ä»¥ä¾¿ä½¿ç”¨æ–°çš„æ¨¡å‹åˆ—è¡¨å’Œå‚æ•°ï¼ˆå¦‚æœç•Œé¢å…è®¸ä¿®æ”¹çš„è¯ï¼‰
                            # å‡è®¾æ¨¡å‹é€‰æ‹©å’Œå‚æ•°ä¸ä¸Šæ¬¡è®­ç»ƒç›¸åŒ
                            models_to_train_iter = st.session_state.get('models_to_train', ["Lasso", "éšæœºæ£®æ—", "XGBoost", "SVR", "é«˜æ–¯è¿‡ç¨‹"]) # è·å–ä¸Šæ¬¡é€‰æ‹©æˆ–é»˜è®¤
                            metric_iter = st.session_state.get('metric', 'r2')
                            cv_folds_iter = st.session_state.get('cv_folds', 5)
                            test_size_iter = st.session_state.get('test_size', 0.2)

                            trainer = ModelTrainer(
                                models=models_to_train_iter,
                                metric=metric_iter.lower(),
                                cv_folds=cv_folds_iter,
                                test_size=test_size_iter
                            )
                            logger.info("å¼€å§‹åœ¨åˆå¹¶æ•°æ®ä¸Šé‡æ–°è®­ç»ƒæ¨¡å‹...")
                            results = trainer.train_and_evaluate(X_combined_scaled, y_combined)
                            logger.info("æ¨¡å‹é‡æ–°è®­ç»ƒå®Œæˆã€‚")

                            # è·å–æœ€ä½³æ¨¡å‹
                            results_df = pd.DataFrame(results).sort_values(
                                by="cv_score",
                                ascending=True if metric_iter.lower() == "rmse" else False
                            )
                            best_model_name = results_df.iloc[0]["model_name"]
                            best_model = trainer.get_best_model()

                            # æ›´æ–°ä¼šè¯çŠ¶æ€
                            st.session_state.model = best_model
                            st.session_state.best_model_name = best_model_name

                            # è·å–å½“å‰æœ€ä½³ç›®æ ‡å€¼ (åœ¨åŸå§‹å°ºåº¦ä¸Š)
                            optimization_direction_iter = st.session_state.get('optimization_direction', "æœ€å¤§åŒ–") # è·å–ä¸Šæ¬¡é€‰æ‹©æˆ–é»˜è®¤
                            best_target = y_combined.max() if optimization_direction_iter == "æœ€å¤§åŒ–" else y_combined.min()

                            # æ›´æ–°ä¼˜åŒ–å†å²
                            st.session_state.optimization_history.append({
                                "data_size": len(combined_data),
                                "best_model": best_model_name,
                                "best_score": float(results_df.iloc[0]["cv_score"]), # ä½¿ç”¨ CV åˆ†æ•°è®°å½•æ€§èƒ½
                                "best_target": float(best_target)
                            })

                            st.success(f"æ¨¡å‹å·²æ›´æ–°ï¼å½“å‰æ•°æ®é›†å¤§å°: {len(combined_data)}")
                            st.info(f"æ–°çš„æœ€ä½³æ¨¡å‹: {best_model_name}")
                            st.info(f"ç‰¹å¾ç¼©æ”¾å™¨ (Scaler) å·²åœ¨åˆå¹¶æ•°æ®ä¸Šé‡æ–°æ‹Ÿåˆã€‚")

                            # æç¤ºç”¨æˆ·ä¸‹ä¸€æ­¥æ“ä½œ
                            st.info("è¯·å‰å¾€'æœç´¢æ¨è'é¡µé¢ç”Ÿæˆæ–°çš„å®éªŒæ¨è")

            except Exception as e:
                error_msg = f"å¤„ç†æ–°æ•°æ®æ—¶å‡ºé”™: {str(e)}"
                logger.error(error_msg, exc_info=True)
                st.error(error_msg)

# å…¨å±€å¼‚å¸¸å¤„ç†ï¼Œç¡®ä¿æ‰€æœ‰æœªæ•è·çš„å¼‚å¸¸éƒ½è¢«è®°å½•
try:
    # ä¸»ç¨‹åºå·²ç»åœ¨ä¸Šé¢è¿è¡Œå®Œæ¯•ï¼Œè¿™é‡Œåªæ˜¯ä¸ºäº†æ•è·å…¨å±€å¼‚å¸¸
    pass
except Exception as e:
    error_msg = f"åº”ç”¨è¿è¡Œæ—¶å‘ç”Ÿæœªæ•è·çš„å¼‚å¸¸: {str(e)}"
    logger.error(error_msg, exc_info=True)
    st.error(error_msg)


# é¡µé¢åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown("Â© 2025 è´å¶æ–¯ä¼˜åŒ–ææ–™ç»„åˆ†ç³»ç»Ÿ | åŸºäºBOçš„ææ–™ä¼˜åŒ–å¹³å° | develop by TTRS-SH ATRD")
